version: "3"

services:

  zookeeper:
    image: confluentinc/cp-zookeeper:7.0.1
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    security_opt:
      - "apparmor=unconfined"
  broker:
    image: confluentinc/cp-kafka:7.0.1
    container_name: broker
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://broker:29092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
    security_opt:
      - "apparmor=unconfined"


  postgres:    
    image: postgres:13-bullseye
    container_name: shopping_cart_postgres
    environment:
      - "TZ=Europe/Amsterdam"
      - "POSTGRES_USER=shopping_cart"
      - "POSTGRES_PASSWORD=shopping_cart"
    ports:
      #- "5432:5432"  # credentials (shopping_cart:shopping_cart)
      - "5433:5432"
  
  spark-master:
    container_name: spark-master
    image: elopezdelara/miniconda3-spark:latest
    expose:
      - "8080"
    ports:
      - "8080:8080"
    command:
      - start-master.sh
    environment:
      - SPARK_NO_DAEMONIZE=1
      - SPARK_PUBLIC_DNS=localhost
    networks:
      - spark-cluster 
    volumes:
      - ./events:/tmp/spark-events

  spark-worker:
    container_name: spark-worker
    depends_on:
      - spark-master
    image: elopezdelara/miniconda3-spark:latest
    expose:
      - "8081"
    ports: 
      - "8081:8081"
    command:
      - start-slave.sh
      - spark://spark-master:7077
    environment:
      - SPARK_NO_DAEMONIZE=1
      - SPARK_PUBLIC_DNS=localhost
    networks:
      - spark-cluster
    volumes:
      - ./events:/tmp/spark-events

  spark-history:
    depends_on:
      - spark-master
    container_name: spark-history
    image: elopezdelara/miniconda3-spark:latest
    expose:
      - "18080"
    ports:
      - "18080:18080"
    command:
      - start-history-server.sh
    environment:
      - SPARK_NO_DAEMONIZE=1
      - SPARK_PUBLIC_DNS=localhost
    networks:
      - spark-cluster
    volumes:
      - ./events:/tmp/spark-events

  jupyter-notebook:
    depends_on:
      - spark-master
    container_name: jupyter-notebook
    image: elopezdelara/miniconda3-spark:latest
    expose:
      - "4040"
      - "8888"
    ports:
      - "4040:4040"
      - "8888:8888"
    networks:
      - spark-cluster
    volumes:
      - ./notebooks:/opt/notebooks
      - ./events:/tmp/spark-events
    command:
      - jupyter
      - notebook
      - --ip='*'
      - --port=8888
      - --no-browser
      - --notebook-dir=/opt/notebooks
      - --allow-root
      - --NotebookApp.token=''

networks:
  spark-cluster:
    name: spark-cluster

#volumes:
#  hadoop_namenode:
#  hadoop_datanode:
#  hadoop_historyserver:
